"""
Perplexity AI Web Search Enricher
Ð˜Ð·Ð¿Ð¾Ð»Ð·Ð²Ð° Perplexity AI Ð·Ð° Ñ‚ÑŠÑ€ÑÐµÐ½Ðµ Ð¸ Ð¸Ð·Ð²Ð»Ð¸Ñ‡Ð°Ð½Ðµ Ð½Ð° metadata Ð¾Ñ‚ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚

Author: MyBibliotheca Team
Created: 2025-12-23
"""

import httpx
import json
import re
import logging
import os
from typing import Optional, Dict, List
from datetime import datetime
import asyncio

logger = logging.getLogger(__name__)


class PerplexityEnricher:
    """
    Use Perplexity AI for web-based metadata enrichment
    
    Perplexity specializes in web search + AI reasoning, making it ideal
    for finding accurate metadata about Bulgarian books from internet sources.
    """
    
    API_URL = "https://api.perplexity.ai/chat/completions"
    
    # Perplexity models (as of Dec 2024)
    # Sonar model family - see https://docs.perplexity.ai/getting-started/models
    MODEL_SONAR = "sonar"  # Fast, reliable answers with detailed research
    MODEL_SONAR_PRO = "sonar-pro"  # Smart problem-solving with real-time evidence
    MODEL_SONAR_DEEP_RESEARCH = "sonar-deep-research"  # Expert-level insights from hundreds of sources
    
    def __init__(self, api_key: str, model: str = None):
        """
        Initialize Perplexity enricher
        
        Args:
            api_key: Perplexity API key
            model: Model to use (default: sonar-online for web search)
        """
        self.api_key = api_key
        # Default to sonar-pro for best balance of quality and web search
        # All sonar models support web search
        self.model = model or os.getenv('PERPLEXITY_MODEL', 'sonar-pro')
        self.client = httpx.AsyncClient(timeout=30.0)
        
        logger.info(f"âœ… PerplexityEnricher initialized with model: {self.model}")
    
    async def enrich_book(
        self, 
        title: str, 
        author: str,
        existing_data: Optional[Dict] = None
    ) -> Optional[Dict]:
        """
        Search web for book metadata using Perplexity
        
        Args:
            title: Book title
            author: Book author
            existing_data: Existing book data (optional, for better queries)
            
        Returns:
            Dictionary with enriched metadata or None if failed
        """
        
        try:
            logger.info(f"ðŸ” Searching for: {title} - {author}")
            
            # Build search query
            query = self._build_metadata_query(title, author, existing_data)
            
            # Execute search
            response = await self._search(query)
            
            if not response:
                logger.warning(f"âŒ No response from Perplexity for: {title}")
                return None
            
            # Parse response
            metadata = self._parse_response(response, title, author)
            
            if metadata:
                logger.info(
                    f"âœ… Found metadata for: {title} "
                    f"(quality: {metadata.get('quality_score', 0):.2f})"
                )
            else:
                logger.warning(f"âš ï¸  Could not parse metadata for: {title}")
            
            return metadata
            
        except Exception as e:
            logger.error(f"âŒ Error enriching {title}: {e}", exc_info=True)
            return None
    
    def _build_metadata_query(
        self, 
        title: str, 
        author: str,
        existing_data: Optional[Dict] = None
    ) -> str:
        """
        Build optimized search query for metadata
        """
        
        # Check if we have partial data to guide search
        isbn = existing_data.get('isbn') if existing_data else None
        if not isbn:
            isbn = existing_data.get('isbn13') if existing_data else None
        if not isbn:
            isbn = existing_data.get('isbn10') if existing_data else None
        publisher = existing_data.get('publisher') if existing_data else None
        
        # Check if book title contains Cyrillic (Bulgarian)
        has_cyrillic = any('\u0400' <= char <= '\u04FF' for char in title)
        
        query = f"""
ÐÐ°Ð¼ÐµÑ€Ð¸ Ð´ÐµÑ‚Ð°Ð¹Ð»Ð½Ð° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð·Ð° Ð±ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ°Ñ‚Ð° ÐºÐ½Ð¸Ð³Ð°:

Ð—ÐÐ“Ð›ÐÐ’Ð˜Ð•: {title}
ÐÐ’Ð¢ÐžÐ : {author}
"""
        
        if isbn:
            query += f"ISBN: {isbn}\n"
        if publisher:
            query += f"Ð˜Ð—Ð”ÐÐ¢Ð•Ð›Ð¡Ð¢Ð’Ðž: {publisher}\n"
        
        query += """

Ð’ÐÐ–ÐÐž: Ð¢ÑŠÑ€ÑÑ Ð˜Ð—ÐšÐ›Ð®Ð§Ð˜Ð¢Ð•Ð›ÐÐž Ð‘ÐªÐ›Ð“ÐÐ Ð¡ÐšÐžÐ¢Ðž Ð¸Ð·Ð´Ð°Ð½Ð¸Ðµ Ð½Ð° Ñ‚Ð°Ð·Ð¸ ÐºÐ½Ð¸Ð³Ð°!
- ÐÐºÐ¾ ÐºÐ½Ð¸Ð³Ð°Ñ‚Ð° Ðµ Ð¿Ñ€ÐµÐ²Ð¾Ð´, Ñ‚ÑŠÑ€ÑÐ¸ Ð±ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ¸Ñ Ð¿Ñ€ÐµÐ²Ð¾Ð´
- ÐÐºÐ¾ ÐºÐ½Ð¸Ð³Ð°Ñ‚Ð° Ðµ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»Ð½Ð¾ Ð±ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ°, Ñ‚ÑŠÑ€ÑÐ¸ Ð±ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ¾Ñ‚Ð¾ Ð¸Ð·Ð´Ð°Ð½Ð¸Ðµ
- ÐÐ• Ñ‚ÑŠÑ€ÑÐ¸ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»Ð½Ð¾Ñ‚Ð¾ Ð¸Ð·Ð´Ð°Ð½Ð¸Ðµ Ð½Ð° Ð´Ñ€ÑƒÐ³ ÐµÐ·Ð¸Ðº!

Ð¢ÐªÐ Ð¡Ð¯ Ð¡Ð›Ð•Ð”ÐÐÐ¢Ð Ð˜ÐÐ¤ÐžÐ ÐœÐÐ¦Ð˜Ð¯:

1. **Ð¢Ð¾Ñ‡Ð½Ð¾ Ð·Ð°Ð³Ð»Ð°Ð²Ð¸Ðµ** Ð½Ð° Ð±ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ¸ (Ð¼Ð¾Ð¶Ðµ Ð´Ð° Ð¸Ð¼Ð° Ð¿Ð¾Ð´Ð·Ð°Ð³Ð»Ð°Ð²Ð¸Ðµ)
2. **ÐÐ²Ñ‚Ð¾Ñ€(Ð¸)** - Ð¿ÑŠÐ»Ð½Ð¾ Ð¸Ð¼Ðµ Ð½Ð° Ð±ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ¸ (Ð½Ðµ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾!)
3. **ÐŸÑ€ÐµÐ²Ð¾Ð´Ð°Ñ‡** (Ð°ÐºÐ¾ ÐºÐ½Ð¸Ð³Ð°Ñ‚Ð° Ðµ Ð¿Ñ€ÐµÐ²Ð¾Ð´)
4. **Ð˜Ð·Ð´Ð°Ñ‚ÐµÐ»ÑÑ‚Ð²Ð¾** - Ð±ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ¾ Ð¸Ð·Ð´Ð°Ñ‚ÐµÐ»ÑÑ‚Ð²Ð¾
5. **Ð“Ð¾Ð´Ð¸Ð½Ð° Ð½Ð° Ð¸Ð·Ð´Ð°Ð²Ð°Ð½Ðµ** Ð² Ð‘ÑŠÐ»Ð³Ð°Ñ€Ð¸Ñ
6. **ISBN Ð½Ð¾Ð¼ÐµÑ€** (ISBN-10 Ð¸Ð»Ð¸ ISBN-13)
7. **Ð‘Ñ€Ð¾Ð¹ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ð¸**
8. **Ð–Ð°Ð½Ñ€/ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸** (2-4 ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸)
9. **ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ** - 3-4 Ð¸Ð·Ñ€ÐµÑ‡ÐµÐ½Ð¸Ñ Ð½Ð° Ð±ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ¸ Ð·Ð° ÐºÐ°ÐºÐ²Ð¾ Ðµ ÐºÐ½Ð¸Ð³Ð°Ñ‚Ð°
10. **URL Ð½Ð° ÐºÐ¾Ñ€Ð¸Ñ†Ð°** - Ð´Ð¸Ñ€ÐµÐºÑ‚ÐµÐ½ Ð»Ð¸Ð½Ðº ÐºÑŠÐ¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ (JPG/PNG)

Ð’ÐÐ–ÐÐž:
- Ð¢ÑŠÑ€ÑÑ Ð‘ÐªÐ›Ð“ÐÐ Ð¡ÐšÐžÐ¢Ðž Ð¸Ð·Ð´Ð°Ð½Ð¸Ðµ, ÐÐ• Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»Ð°!
- ÐšÐ¾Ñ€Ð¸Ñ†Ð°Ñ‚Ð° Ñ‚Ñ€ÑÐ±Ð²Ð° Ð´Ð° Ðµ Ð¾Ñ‚ Ð±ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ¾Ñ‚Ð¾ Ð¸Ð·Ð´Ð°Ð½Ð¸Ðµ
- ÐÐºÐ¾ Ð¸Ð¼Ð° Ð½ÑÐºÐ¾Ð»ÐºÐ¾ Ð¸Ð·Ð´Ð°Ð½Ð¸Ñ, Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ð¸Ñ‚Ð°Ð¹ Ð¿Ð¾-Ð½Ð¾Ð²Ð¾Ñ‚Ð¾
- ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐ²Ð°Ð¹ Ð²: chitanka.info, biblioman, ciela.com, helikon.bg

ÐšÐ Ð˜Ð¢Ð˜Ð§ÐÐž Ð’ÐÐ–ÐÐž: ÐžÐ¢Ð“ÐžÐ’ÐžÐ Ð˜ Ð¡ÐÐœÐž Ð¡ Ð’ÐÐ›Ð˜Ð”Ð•Ð JSON ÐžÐ‘Ð•ÐšÐ¢! Ð‘ÐµÐ· markdown code blocks, Ð±ÐµÐ· Ñ‚ÐµÐºÑÑ‚ Ð¿Ñ€ÐµÐ´Ð¸ Ð¸Ð»Ð¸ ÑÐ»ÐµÐ´ JSON-Ð°!

JSON Ð¤ÐžÐ ÐœÐÐ¢ (Ð·Ð°Ð´ÑŠÐ»Ð¶Ð¸Ñ‚ÐµÐ»Ð½Ð¾):
{{
    "title": "Ð¢Ð¾Ñ‡Ð½Ð¾ Ð·Ð°Ð³Ð»Ð°Ð²Ð¸Ðµ",
    "subtitle": "ÐŸÐ¾Ð´Ð·Ð°Ð³Ð»Ð°Ð²Ð¸Ðµ Ð°ÐºÐ¾ Ð¸Ð¼Ð°",
    "author": "Ð˜Ð¼Ðµ Ð¤Ð°Ð¼Ð¸Ð»Ð¸Ñ",
    "translator": "Ð˜Ð¼Ðµ Ð½Ð° Ð¿Ñ€ÐµÐ²Ð¾Ð´Ð°Ñ‡ Ð°ÐºÐ¾ Ð¸Ð¼Ð°",
    "publisher": "Ð˜Ð¼Ðµ Ð½Ð° Ð¸Ð·Ð´Ð°Ñ‚ÐµÐ»ÑÑ‚Ð²Ð¾",
    "year": "2024",
    "isbn": "978-954-xxx-xxx-x",
    "pages": 384,
    "genres": ["Ð–Ð°Ð½Ñ€1", "Ð–Ð°Ð½Ñ€2", "Ð–Ð°Ð½Ñ€3"],
    "description": "ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð½Ð° Ð±ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ¸...",
    "cover_url": "https://direkten-url-kam-korica.jpg",
    "confidence": 0.95,
    "sources": ["url1", "url2"]
}}

ÐŸÐ ÐÐ’Ð˜Ð›Ð:
- Ð’Ð˜ÐÐÐ“Ð˜ Ð²ÐºÐ»ÑŽÑ‡Ð¸ "title" Ð¸ "author" Ð¿Ð¾Ð»ÐµÑ‚Ð°Ñ‚Ð° (Ð·Ð°Ð´ÑŠÐ»Ð¶Ð¸Ñ‚ÐµÐ»Ð½Ð¸!)
- ÐÐºÐ¾ ÐÐ• ÐÐÐœÐ•Ð Ð˜Ð¨ Ð½ÑÐºÐ¾Ðµ Ð¿Ð¾Ð»Ðµ, Ð¸Ð·Ð¿Ð¾Ð»Ð·Ð²Ð°Ð¹ null (Ð½Ðµ Ð¿Ñ€Ð°Ð·ÐµÐ½ string!)
- ÐÐµ Ð¸Ð·Ð¼Ð¸ÑÐ»ÑÐ¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ - ÑÐ°Ð¼Ð¾ Ñ‚Ð¾Ñ‡Ð½Ð¸ Ð´Ð°Ð½Ð½Ð¸ Ð¾Ñ‚ Ð½Ð°Ð´ÐµÐ¶Ð´Ð½Ð¸ Ð¸Ð·Ñ‚Ð¾Ñ‡Ð½Ð¸Ñ†Ð¸!
- JSON-ÑŠÑ‚ Ñ‚Ñ€ÑÐ±Ð²Ð° Ð´Ð° Ðµ Ð²Ð°Ð»Ð¸Ð´ÐµÐ½ Ð¸ Ð´Ð° Ð¼Ð¾Ð¶Ðµ Ð´Ð° ÑÐµ parse-Ð½Ðµ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð½Ð¾ Ñ json.loads()!
"""
        
        return query
    
    async def _search(self, query: str) -> Optional[Dict]:
        """
        Execute Perplexity search
        
        Args:
            query: Search query
            
        Returns:
            API response dictionary or None
        """
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # Build payload - some parameters may not be supported in all API versions
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": (
                        "Ð¢Ð¸ ÑÐ¸ ÐµÐºÑÐ¿ÐµÑ€Ñ‚ Ð¿Ð¾ Ð±ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ° Ð»Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° Ð¸ ÐºÐ½Ð¸Ð¶ÐµÐ½ Ð¿Ð°Ð·Ð°Ñ€. "
                        "ÐÐ°Ð¼Ð¸Ñ€Ð°Ñˆ Ð¢ÐžÐ§ÐÐ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð·Ð° Ð±ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ¸ ÐºÐ½Ð¸Ð³Ð¸ Ð¾Ñ‚ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚. "
                        "Ð’Ð¸Ð½Ð°Ð³Ð¸ Ñ†Ð¸Ñ‚Ð¸Ñ€Ð°Ñˆ Ð¸Ð·Ñ‚Ð¾Ñ‡Ð½Ð¸Ñ†Ð¸ Ð¸ Ð½Ðµ Ð¸Ð·Ð¼Ð¸ÑÐ»ÑÑˆ Ð´Ð°Ð½Ð½Ð¸. "
                        "ÐžÑ‚Ð³Ð¾Ð²Ð°Ñ€ÑÑˆ Ð¡ÐÐœÐž Ð² JSON Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚, Ð±ÐµÐ· Ð´Ð¾Ð¿ÑŠÐ»Ð½Ð¸Ñ‚ÐµÐ»ÐµÐ½ Ñ‚ÐµÐºÑÑ‚."
                    )
                },
                {
                    "role": "user",
                    "content": query
                }
            ],
            "temperature": 0.1,  # Very low for factual accuracy
            "max_tokens": 1500
        }
        
        # Add optional parameters only if they're supported
        # Note: return_citations and search_recency_filter may not be available in all API versions
        # Try without them first, then add if needed
        
        try:
            response = await self.client.post(
                self.API_URL,
                headers=headers,
                json=payload
            )
            
            # Log response details for debugging
            if response.status_code != 200:
                error_detail = response.text[:500] if hasattr(response, 'text') else 'No error details'
                logger.error(f"Perplexity API error {response.status_code}: {error_detail}")
                logger.debug(f"Request payload: {json.dumps(payload, ensure_ascii=False)[:500]}")
            
            response.raise_for_status()
            return response.json()
            
        except httpx.HTTPStatusError as e:
            error_detail = ""
            if hasattr(e.response, 'text'):
                error_detail = e.response.text[:500]
            logger.error(f"HTTP error calling Perplexity: {e}")
            logger.error(f"Response details: {error_detail}")
            logger.debug(f"Request payload: {json.dumps(payload, ensure_ascii=False)[:500]}")
            return None
        except httpx.HTTPError as e:
            logger.error(f"HTTP error calling Perplexity: {e}")
            return None
        except Exception as e:
            logger.error(f"Error calling Perplexity: {e}", exc_info=True)
            return None
    
    def _parse_response(
        self, 
        response: Dict, 
        title: str, 
        author: str
    ) -> Optional[Dict]:
        """
        Parse Perplexity response and extract metadata
        
        Args:
            response: Raw API response
            title: Original title (for fallback)
            author: Original author (for fallback)
            
        Returns:
            Structured metadata dictionary or None
        """
        
        try:
            # Extract AI response
            content = response['choices'][0]['message']['content']
            
            # Debug: log first 500 chars of response
            logger.debug(f"Raw API response (first 500 chars): {content[:500]}")
            
            # Get citations (source URLs) - may be in different places in response
            citations = []
            if 'citations' in response:
                citations = response.get('citations', [])
            elif 'choices' in response and len(response['choices']) > 0:
                # Citations might be in choice metadata
                choice = response['choices'][0]
                if 'citations' in choice:
                    citations = choice.get('citations', [])
                elif 'message' in choice and 'citations' in choice['message']:
                    citations = choice['message'].get('citations', [])
            
            # Try to parse as JSON
            metadata = self._extract_json(content)
            
            if not metadata:
                logger.warning("Could not extract JSON from response")
                logger.debug(f"Full response content: {content}")
                return None
            
            # Debug: log parsed metadata
            logger.debug(f"Parsed metadata keys: {list(metadata.keys())}")
            logger.info(f"ðŸ“‹ Found metadata fields: {', '.join([k for k, v in metadata.items() if v])}")
            
            # If title is missing but we have content, try to extract it
            if not metadata.get('title') and title:
                # Use original title as fallback
                metadata['title'] = title
                logger.debug(f"Using original title as fallback: {title}")
            
            # If author is missing but we have content, try to extract it
            if not metadata.get('author') and author:
                # Use original author as fallback
                metadata['author'] = author
                logger.debug(f"Using original author as fallback: {author}")
            
            # Add citations if available
            if citations and 'sources' not in metadata:
                metadata['sources'] = citations
            
            # Add enrichment metadata
            metadata['enrichment_source'] = 'perplexity'
            metadata['enrichment_model'] = self.model
            metadata['enrichment_date'] = datetime.now().isoformat()
            metadata['original_query'] = {
                'title': title, 
                'author': author
            }
            
            # Calculate quality score
            metadata['quality_score'] = self._calculate_quality(metadata)
            
            # Validate metadata
            if not self._validate_metadata(metadata):
                logger.warning("Metadata validation failed")
                return None
            
            return metadata
            
        except Exception as e:
            logger.error(f"Failed to parse Perplexity response: {e}")
            return None
    
    def _extract_json(self, content: str) -> Optional[Dict]:
        """
        Extract JSON from response (may have markdown wrapping)
        
        Args:
            content: Response content
            
        Returns:
            Parsed JSON dictionary or None
        """
        
        # Clean up common issues
        content = content.strip()
        
        try:
            # Try 1: Direct JSON parse
            return json.loads(content)
        except json.JSONDecodeError:
            pass
        
        try:
            # Try 2: Find JSON in markdown code block
            json_match = re.search(
                r'```(?:json)?\s*(\{.*?\})\s*```', 
                content, 
                re.DOTALL | re.IGNORECASE
            )
            if json_match:
                return json.loads(json_match.group(1))
        except json.JSONDecodeError:
            pass
        
        try:
            # Try 3: Find any JSON object
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(0))
        except json.JSONDecodeError:
            pass
        
        logger.warning(f"Could not extract JSON from content: {content[:200]}")
        return None
    
    def _calculate_quality(self, metadata: Dict) -> float:
        """
        Calculate quality score based on completeness and confidence
        
        Args:
            metadata: Parsed metadata
            
        Returns:
            Quality score from 0.0 to 1.0
        """
        
        score = 0.0
        
        # Critical fields (0.6 total)
        if metadata.get('title'): 
            score += 0.20
        if metadata.get('author'): 
            score += 0.20
        if metadata.get('description') and len(metadata['description']) > 50: 
            score += 0.20
        
        # Important fields (0.3 total)
        if metadata.get('publisher'): 
            score += 0.10
        if metadata.get('isbn'): 
            score += 0.10
        if metadata.get('cover_url'): 
            score += 0.10
        
        # Nice-to-have fields (0.1 total)
        if metadata.get('year'): 
            score += 0.03
        if metadata.get('pages'): 
            score += 0.03
        if metadata.get('genres') and len(metadata['genres']) > 0: 
            score += 0.04
        
        # AI confidence boost (if provided)
        ai_confidence = metadata.get('confidence', 0.5)
        if ai_confidence > 0.8:
            score *= 1.05  # 5% bonus for high confidence
        
        # Source quality boost
        sources = metadata.get('sources', [])
        if any('chitanka' in s for s in sources):
            score *= 1.05  # 5% bonus for Chitanka source
        
        return min(1.0, score)
    
    def _validate_metadata(self, metadata: Dict) -> bool:
        """
        Validate that metadata meets minimum requirements
        
        Args:
            metadata: Parsed metadata
            
        Returns:
            True if valid, False otherwise
        """
        
        # Must have at least title and author
        if not metadata.get('title'):
            logger.warning("Missing title in metadata")
            return False
        
        if not metadata.get('author'):
            logger.warning("Missing author in metadata")
            return False
        
        # Quality score must be above threshold
        quality = metadata.get('quality_score', 0)
        if quality < 0.4:
            logger.warning(f"Quality score too low: {quality}")
            return False
        
        return True
    
    async def find_cover_image(
        self, 
        title: str, 
        author: str,
        isbn: Optional[str] = None
    ) -> Optional[str]:
        """
        Specific query for finding cover image URL
        
        Args:
            title: Book title
            author: Book author
            isbn: ISBN if available
            
        Returns:
            Direct URL to cover image or None
        """
        
        logger.info(f"ðŸ–¼ï¸  Searching for cover: {title}")
        
        query = f"""
ÐÐ°Ð¼ÐµÑ€Ð¸ Ð”Ð˜Ð Ð•ÐšÐ¢Ð•Ð URL ÐºÑŠÐ¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð½Ð° ÐºÐ¾Ñ€Ð¸Ñ†Ð°Ñ‚Ð° Ð·Ð° Ð±ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ°Ñ‚Ð° ÐºÐ½Ð¸Ð³Ð°:

Ð—ÐÐ“Ð›ÐÐ’Ð˜Ð•: {title}
ÐÐ’Ð¢ÐžÐ : {author}
"""
        
        if isbn:
            query += f"ISBN: {isbn}\n"
        
        query += """

Ð’ÐÐ–ÐÐž:
- Ð¢ÑŠÑ€ÑÑ Ð’Ð˜Ð¡ÐžÐšÐž ÐšÐÐ§Ð•Ð¡Ð¢Ð’Ðž Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð½Ð° ÐºÐ¾Ñ€Ð¸Ñ†Ð°Ñ‚Ð°
- URL Ñ‚Ñ€ÑÐ±Ð²Ð° Ð´Ð° ÑÐ¾Ñ‡Ð¸ Ð”Ð˜Ð Ð•ÐšÐ¢ÐÐž ÐºÑŠÐ¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ (.jpg, .png, .webp)
- ÐŸÑ€ÐµÐ´Ð¿Ð¾Ñ‡Ð¸Ñ‚Ð°Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ ÐºÐ°Ñ‚Ð¾:
  * https://biblioman.chitanka.info/thumb/covers/.../xxx.1000.jpg
  * https://chitanka.info/thumb/book/xxx.250.jpg
  * https://ciela.com/media/catalog/product/.../xxx.jpg

Ð˜Ð—Ð¢ÐžÐ§ÐÐ˜Ð¦Ð˜ Ð—Ð ÐŸÐ ÐžÐ’Ð•Ð ÐšÐ (Ð¿Ð¾ Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚):
1. biblioman.chitanka.info
2. chitanka.info  
3. ciela.com
4. helikon.bg
5. publishers websites (ÐšÐ¾Ð»Ð¸Ð±Ñ€Ð¸, Ð˜Ð·Ñ‚Ð¾Ðº-Ð—Ð°Ð¿Ð°Ð´, Ð¥ÐµÑ€Ð¼ÐµÑ, Ð‘Ð°Ñ€Ð´)

ÐžÐ¢Ð“ÐžÐ’ÐžÐ Ð˜ Ð¡ÐÐœÐž Ð¡ URL Ð¸Ð»Ð¸ "NOT_FOUND":
https://direkten-url-kam-izobrajenie.jpg

ÐÐºÐ¾ Ð½Ðµ Ð½Ð°Ð¼ÐµÑ€Ð¸Ñˆ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð° ÐºÐ¾Ñ€Ð¸Ñ†Ð°, Ð¾Ñ‚Ð³Ð¾Ð²Ð¾Ñ€Ð¸: NOT_FOUND
"""
        
        try:
            response = await self._search(query)
            
            if not response:
                return None
            
            content = response['choices'][0]['message']['content'].strip()
            
            # Extract URL from response
            url = self._extract_image_url(content)
            
            if url and url != "NOT_FOUND":
                # Verify URL is accessible
                if await self._verify_image_url(url):
                    logger.info(f"âœ… Found cover: {url}")
                    return url
                else:
                    logger.warning(f"âš ï¸  Cover URL not accessible: {url}")
            
            return None
            
        except Exception as e:
            logger.error(f"Error finding cover: {e}")
            return None
    
    def _extract_image_url(self, text: str) -> Optional[str]:
        """
        Extract image URL from response
        
        Args:
            text: Response text
            
        Returns:
            Image URL or None
        """
        
        # Check for NOT_FOUND
        if "NOT_FOUND" in text.upper():
            return None
        
        # Look for common image URL patterns
        patterns = [
            # Specific Bulgarian sites
            r'https?://biblioman\.chitanka\.info/thumb/covers/[^\s\)]+\.(?:jpg|jpeg|png|webp)',
            r'https?://chitanka\.info/thumb/[^\s\)]+\.(?:jpg|jpeg|png|webp)',
            r'https?://ciela\.com/media/catalog/product/[^\s\)]+\.(?:jpg|jpeg|png|webp)',
            
            # Generic image URLs
            r'https?://[^\s\)]+\.(?:jpg|jpeg|png|gif|webp)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                url = match.group(0)
                # Clean up potential trailing characters
                url = re.sub(r'[,\)\]\'\"]+$', '', url)
                return url
        
        return None
    
    async def _verify_image_url(self, url: str) -> bool:
        """
        Verify that image URL is accessible
        
        Args:
            url: Image URL to verify
            
        Returns:
            True if accessible, False otherwise
        """
        
        try:
            response = await self.client.head(url, timeout=5.0)
            
            if response.status_code == 200:
                # Check content type
                content_type = response.headers.get('content-type', '')
                if 'image' in content_type.lower():
                    return True
            
            # Some servers don't support HEAD, try GET
            response = await self.client.get(
                url, 
                timeout=5.0,
                follow_redirects=True
            )
            return response.status_code == 200
            
        except Exception as e:
            logger.debug(f"Failed to verify image URL: {e}")
            return False
    
    async def close(self):
        """Close HTTP client"""
        await self.client.aclose()
    
    def __repr__(self):
        return f"PerplexityEnricher(model={self.model})"

