"""
Perplexity AI Web Search Enricher
–ò–∑–ø–æ–ª–∑–≤–∞ Perplexity AI –∑–∞ —Ç—ä—Ä—Å–µ–Ω–µ –∏ –∏–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ metadata –æ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç

Author: MyBibliotheca Team
Created: 2025-12-23
"""

import httpx
import json
import re
import logging
import os
from typing import Optional, Dict, List
from datetime import datetime
import asyncio

logger = logging.getLogger(__name__)


class PerplexityEnricher:
    """
    Use Perplexity AI for web-based metadata enrichment
    
    Perplexity specializes in web search + AI reasoning, making it ideal
    for finding accurate metadata about Bulgarian books from internet sources.
    """
    
    API_URL = "https://api.perplexity.ai/chat/completions"
    
    # Perplexity models (as of Dec 2024)
    # Sonar model family - see https://docs.perplexity.ai/getting-started/models
    MODEL_SONAR = "sonar"  # Fast, reliable answers with detailed research
    MODEL_SONAR_PRO = "sonar-pro"  # Smart problem-solving with real-time evidence
    MODEL_SONAR_DEEP_RESEARCH = "sonar-deep-research"  # Expert-level insights from hundreds of sources
    
    def __init__(self, api_key: str, model: str = None):
        """
        Initialize Perplexity enricher
        
        Args:
            api_key: Perplexity API key
            model: Model to use (default: sonar-online for web search)
        """
        self.api_key = api_key
        # Default to sonar-pro for best balance of quality and web search
        # All sonar models support web search
        self.model = model or os.getenv('PERPLEXITY_MODEL', 'sonar-pro')
        self.client = httpx.AsyncClient(timeout=30.0)
        
        logger.info(f"‚úÖ PerplexityEnricher initialized with model: {self.model}")
    
    async def enrich_book(
        self, 
        title: str, 
        author: str,
        existing_data: Optional[Dict] = None
    ) -> Optional[Dict]:
        """
        Search web for book metadata using Perplexity
        
        Args:
            title: Book title
            author: Book author
            existing_data: Existing book data (optional, for better queries)
            
        Returns:
            Dictionary with enriched metadata or None if failed
        """
        
        try:
            logger.info(f"üîç Searching for: {title} - {author}")
            
            # Build search query
            query = self._build_metadata_query(title, author, existing_data)
            
            # Execute search
            response = await self._search(query)
            
            if not response:
                logger.warning(f"‚ùå No response from Perplexity for: {title}")
                return None
            
            # Parse response
            metadata = self._parse_response(response, title, author)
            
            if metadata:
                logger.info(
                    f"‚úÖ Found metadata for: {title} "
                    f"(quality: {metadata.get('quality_score', 0):.2f})"
                )
            else:
                logger.warning(f"‚ö†Ô∏è  Could not parse metadata for: {title}")
            
            return metadata
            
        except Exception as e:
            logger.error(f"‚ùå Error enriching {title}: {e}", exc_info=True)
            return None
    
    def _build_metadata_query(
        self, 
        title: str, 
        author: str,
        existing_data: Optional[Dict] = None
    ) -> str:
        """
        Build optimized search query for metadata
        """
        
        # Check if we have partial data to guide search
        isbn = existing_data.get('isbn') if existing_data else None
        if not isbn:
            isbn = existing_data.get('isbn13') if existing_data else None
        if not isbn:
            isbn = existing_data.get('isbn10') if existing_data else None
        publisher = existing_data.get('publisher') if existing_data else None
        
        # Check if book title contains Cyrillic (Bulgarian)
        has_cyrillic = any('\u0400' <= char <= '\u04FF' for char in title)
        
        # Normalize author - if multiple authors, try to find the main one
        # For Bulgarian books, prefer Bulgarian name format
        import re
        author_normalized = author
        if ',' in author or ';' in author:
            # Multiple authors - try to extract main author
            authors_list = [a.strip() for a in re.split(r'[,;]', author)]
            # For Bulgarian books, prefer Cyrillic name
            cyrillic_authors = [a for a in authors_list if any('\u0400' <= char <= '\u04FF' for char in a)]
            if cyrillic_authors:
                author_normalized = cyrillic_authors[0]  # Use first Bulgarian name
            else:
                author_normalized = authors_list[0]  # Use first author
        
        # Build query - handle missing author
        if author_normalized and author_normalized.strip():
            query = f"""
–ù–∞–º–µ—Ä–∏ –¥–µ—Ç–∞–π–ª–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∞—Ç–∞ –∫–Ω–∏–≥–∞:

–ó–ê–ì–õ–ê–í–ò–ï: {title}
–ê–í–¢–û–†: {author_normalized}
"""
        else:
            # No author provided - AI should find it
            query = f"""
–ù–∞–º–µ—Ä–∏ –¥–µ—Ç–∞–π–ª–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∞—Ç–∞ –∫–Ω–∏–≥–∞:

–ó–ê–ì–õ–ê–í–ò–ï: {title}

–í–ê–ñ–ù–û: –ê–∫–æ –∑–Ω–∞–µ—à –∞–≤—Ç–æ—Ä–∞ –Ω–∞ —Ç–∞–∑–∏ –∫–Ω–∏–≥–∞, –≤–∫–ª—é—á–∏ –≥–æ –≤ –æ—Ç–≥–æ–≤–æ—Ä–∞!
"""
        
        if isbn:
            query += f"ISBN: {isbn}\n"
        if publisher:
            query += f"–ò–ó–î–ê–¢–ï–õ–°–¢–í–û: {publisher}\n"
        
        query += """

–í–ê–ñ–ù–û: –¢—ä—Ä—Å—è –ò–ó–ö–õ–Æ–ß–ò–¢–ï–õ–ù–û –ë–™–õ–ì–ê–†–°–ö–û–¢–û –∏–∑–¥–∞–Ω–∏–µ –Ω–∞ —Ç–∞–∑–∏ –∫–Ω–∏–≥–∞!
- –ê–∫–æ –∫–Ω–∏–≥–∞—Ç–∞ –µ –ø—Ä–µ–≤–æ–¥, —Ç—ä—Ä—Å–∏ –±—ä–ª–≥–∞—Ä—Å–∫–∏—è –ø—Ä–µ–≤–æ–¥
- –ê–∫–æ –∫–Ω–∏–≥–∞—Ç–∞ –µ –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–æ –±—ä–ª–≥–∞—Ä—Å–∫–∞, —Ç—ä—Ä—Å–∏ –±—ä–ª–≥–∞—Ä—Å–∫–æ—Ç–æ –∏–∑–¥–∞–Ω–∏–µ
- –ù–ï —Ç—ä—Ä—Å–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–æ—Ç–æ –∏–∑–¥–∞–Ω–∏–µ –Ω–∞ –¥—Ä—É–≥ –µ–∑–∏–∫!

–¢–™–†–°–Ø –°–õ–ï–î–ù–ê–¢–ê –ò–ù–§–û–†–ú–ê–¶–ò–Ø:

1. **–¢–æ—á–Ω–æ –∑–∞–≥–ª–∞–≤–∏–µ** –Ω–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏ (–º–æ–∂–µ –¥–∞ –∏–º–∞ –ø–æ–¥–∑–∞–≥–ª–∞–≤–∏–µ)
2. **–ê–≤—Ç–æ—Ä** - –ï–î–ò–ù –æ—Å–Ω–æ–≤–µ–Ω –∞–≤—Ç–æ—Ä –Ω–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏ (–Ω–µ –∞–Ω–≥–ª–∏–π—Å–∫–æ!). –ê–∫–æ –∫–Ω–∏–≥–∞—Ç–∞ –µ –æ—Ç –ê–≥–∞—Ç–∞ –ö—Ä–∏—Å—Ç–∏, –∞–≤—Ç–æ—Ä—ä—Ç –µ "–ê–≥–∞—Ç–∞ –ö—Ä–∏—Å—Ç–∏" (–Ω–µ "Christie, Agatha" –∏–ª–∏ –¥—Ä—É–≥–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∏!)
3. **–ü—Ä–µ–≤–æ–¥–∞—á** (–∞–∫–æ –∫–Ω–∏–≥–∞—Ç–∞ –µ –ø—Ä–µ–≤–æ–¥)
4. **–ò–∑–¥–∞—Ç–µ–ª—Å—Ç–≤–æ** - –±—ä–ª–≥–∞—Ä—Å–∫–æ –∏–∑–¥–∞—Ç–µ–ª—Å—Ç–≤–æ
5. **–ì–æ–¥–∏–Ω–∞ –Ω–∞ –∏–∑–¥–∞–≤–∞–Ω–µ** –≤ –ë—ä–ª–≥–∞—Ä–∏—è
6. **ISBN –Ω–æ–º–µ—Ä** (ISBN-10 –∏–ª–∏ ISBN-13)
7. **–ë—Ä–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–∏**
8. **–ñ–∞–Ω—Ä/–ö–∞—Ç–µ–≥–æ—Ä–∏–∏** (2-4 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)
9. **–û–ø–∏—Å–∞–Ω–∏–µ** - 3-4 –∏–∑—Ä–µ—á–µ–Ω–∏—è –Ω–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏ –∑–∞ –∫–∞–∫–≤–æ –µ –∫–Ω–∏–≥–∞—Ç–∞
10. **URL –Ω–∞ –∫–æ—Ä–∏—Ü–∞** - –¥–∏—Ä–µ–∫—Ç–µ–Ω –ª–∏–Ω–∫ –∫—ä–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (JPG/PNG)

–í–ê–ñ–ù–û:
- –¢—ä—Ä—Å—è –ë–™–õ–ì–ê–†–°–ö–û–¢–û –∏–∑–¥–∞–Ω–∏–µ, –ù–ï –æ—Ä–∏–≥–∏–Ω–∞–ª–∞!
- –ö–æ—Ä–∏—Ü–∞—Ç–∞ —Ç—Ä—è–±–≤–∞ –¥–∞ –µ –æ—Ç –±—ä–ª–≥–∞—Ä—Å–∫–æ—Ç–æ –∏–∑–¥–∞–Ω–∏–µ
- –ê–∫–æ –∏–º–∞ –Ω—è–∫–æ–ª–∫–æ –∏–∑–¥–∞–Ω–∏—è, –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–π –ø–æ-–Ω–æ–≤–æ—Ç–æ
- –ü—Ä–æ–≤–µ—Ä—è–≤–∞–π –≤: chitanka.info, biblioman, ciela.com, helikon.bg

–ö–†–ò–¢–ò–ß–ù–û –í–ê–ñ–ù–û: –û–¢–ì–û–í–û–†–ò –°–ê–ú–û –° –í–ê–õ–ò–î–ï–ù JSON –û–ë–ï–ö–¢! –ë–µ–∑ markdown code blocks, –±–µ–∑ —Ç–µ–∫—Å—Ç –ø—Ä–µ–¥–∏ –∏–ª–∏ —Å–ª–µ–¥ JSON-–∞!

JSON –§–û–†–ú–ê–¢ (–∑–∞–¥—ä–ª–∂–∏—Ç–µ–ª–Ω–æ):
{{
    "title": "–¢–æ—á–Ω–æ –∑–∞–≥–ª–∞–≤–∏–µ",
    "subtitle": "–ü–æ–¥–∑–∞–≥–ª–∞–≤–∏–µ –∞–∫–æ –∏–º–∞",
    "author": "–ò–º–µ –§–∞–º–∏–ª–∏—è",
    "translator": "–ò–º–µ –Ω–∞ –ø—Ä–µ–≤–æ–¥–∞—á –∞–∫–æ –∏–º–∞",
    "publisher": "–ò–º–µ –Ω–∞ –∏–∑–¥–∞—Ç–µ–ª—Å—Ç–≤–æ",
    "year": "2024",
    "isbn": "978-954-xxx-xxx-x",
    "pages": 384,
    "genres": ["–ñ–∞–Ω—Ä1", "–ñ–∞–Ω—Ä2", "–ñ–∞–Ω—Ä3"],
    "description": "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏...",
    "cover_url": "https://direkten-url-kam-korica.jpg",
    "confidence": 0.95,
    "sources": ["url1", "url2"]
}}

–ü–†–ê–í–ò–õ–ê:
- –í–ò–ù–ê–ì–ò –≤–∫–ª—é—á–∏ "title" –∏ "author" –ø–æ–ª–µ—Ç–∞—Ç–∞ (–∑–∞–¥—ä–ª–∂–∏—Ç–µ–ª–Ω–∏!)
- –ê–∫–æ –ù–ï –ù–ê–ú–ï–†–ò–® –Ω—è–∫–æ–µ –ø–æ–ª–µ, –∏–∑–ø–æ–ª–∑–≤–∞–π null (–Ω–µ –ø—Ä–∞–∑–µ–Ω string!)
- –ù–µ –∏–∑–º–∏—Å–ª—è–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è - —Å–∞–º–æ —Ç–æ—á–Ω–∏ –¥–∞–Ω–Ω–∏ –æ—Ç –Ω–∞–¥–µ–∂–¥–Ω–∏ –∏–∑—Ç–æ—á–Ω–∏—Ü–∏!
- JSON-—ä—Ç —Ç—Ä—è–±–≤–∞ –¥–∞ –µ –≤–∞–ª–∏–¥–µ–Ω –∏ –¥–∞ –º–æ–∂–µ –¥–∞ —Å–µ parse-–Ω–µ –¥–∏—Ä–µ–∫—Ç–Ω–æ —Å json.loads()!
"""
        
        return query
    
    async def _search(self, query: str) -> Optional[Dict]:
        """
        Execute Perplexity search
        
        Args:
            query: Search query
            
        Returns:
            API response dictionary or None
        """
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # Build payload - some parameters may not be supported in all API versions
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": (
                        "–¢–∏ —Å–∏ –µ–∫—Å–ø–µ—Ä—Ç –ø–æ –±—ä–ª–≥–∞—Ä—Å–∫–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞ –∏ –∫–Ω–∏–∂–µ–Ω –ø–∞–∑–∞—Ä. "
                        "–ù–∞–º–∏—Ä–∞—à –¢–û–ß–ù–ê –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏ –∫–Ω–∏–≥–∏ –æ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç. "
                        "–í–∏–Ω–∞–≥–∏ —Ü–∏—Ç–∏—Ä–∞—à –∏–∑—Ç–æ—á–Ω–∏—Ü–∏ –∏ –Ω–µ –∏–∑–º–∏—Å–ª—è—à –¥–∞–Ω–Ω–∏. "
                        "–û—Ç–≥–æ–≤–∞—Ä—è—à –°–ê–ú–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç, –±–µ–∑ –¥–æ–ø—ä–ª–Ω–∏—Ç–µ–ª–µ–Ω —Ç–µ–∫—Å—Ç."
                    )
                },
                {
                    "role": "user",
                    "content": query
                }
            ],
            "temperature": 0.1,  # Very low for factual accuracy
            "max_tokens": 1500
        }
        
        # Add optional parameters only if they're supported
        # Note: return_citations and search_recency_filter may not be available in all API versions
        # Try without them first, then add if needed
        
        try:
            response = await self.client.post(
                self.API_URL,
                headers=headers,
                json=payload
            )
            
            # Log response details for debugging
            if response.status_code != 200:
                error_detail = response.text[:500] if hasattr(response, 'text') else 'No error details'
                logger.error(f"Perplexity API error {response.status_code}: {error_detail}")
                logger.debug(f"Request payload: {json.dumps(payload, ensure_ascii=False)[:500]}")
            
            response.raise_for_status()
            return response.json()
            
        except httpx.HTTPStatusError as e:
            error_detail = ""
            if hasattr(e.response, 'text'):
                error_detail = e.response.text[:500]
            logger.error(f"HTTP error calling Perplexity: {e}")
            logger.error(f"Response details: {error_detail}")
            logger.debug(f"Request payload: {json.dumps(payload, ensure_ascii=False)[:500]}")
            return None
        except httpx.HTTPError as e:
            logger.error(f"HTTP error calling Perplexity: {e}")
            return None
        except Exception as e:
            logger.error(f"Error calling Perplexity: {e}", exc_info=True)
            return None
    
    def _parse_response(
        self, 
        response: Dict, 
        title: str, 
        author: str
    ) -> Optional[Dict]:
        """
        Parse Perplexity response and extract metadata
        
        Args:
            response: Raw API response
            title: Original title (for fallback)
            author: Original author (for fallback)
            
        Returns:
            Structured metadata dictionary or None
        """
        
        try:
            # Extract AI response
            content = response['choices'][0]['message']['content']
            
            # Debug: log first 500 chars of response
            logger.debug(f"Raw API response (first 500 chars): {content[:500]}")
            
            # Get citations (source URLs) - may be in different places in response
            citations = []
            if 'citations' in response:
                citations = response.get('citations', [])
            elif 'choices' in response and len(response['choices']) > 0:
                # Citations might be in choice metadata
                choice = response['choices'][0]
                if 'citations' in choice:
                    citations = choice.get('citations', [])
                elif 'message' in choice and 'citations' in choice['message']:
                    citations = choice['message'].get('citations', [])
            
            # Try to parse as JSON
            metadata = self._extract_json(content)
            
            if not metadata:
                logger.warning("Could not extract JSON from response")
                logger.debug(f"Full response content: {content}")
                return None
            
            # Clean description - remove citation markers like [3][5][7][9]
            if metadata.get('description'):
                description = metadata['description']
                # Remove citation patterns like [1], [2][3], [1][2][3][4], etc.
                description = re.sub(r'\[\d+\]', '', description)
                # Clean up multiple spaces
                description = re.sub(r'\s+', ' ', description).strip()
                metadata['description'] = description
            
            # Debug: log parsed metadata
            logger.debug(f"Parsed metadata keys: {list(metadata.keys())}")
            logger.info(f"üìã Found metadata fields: {', '.join([k for k, v in metadata.items() if v])}")
            
            # If title is missing but we have content, try to extract it
            if not metadata.get('title') and title:
                # Use original title as fallback
                metadata['title'] = title
                logger.debug(f"Using original title as fallback: {title}")
            
            # Normalize author - ensure single main author
            if metadata.get('author'):
                author_from_ai = metadata['author']
                # If multiple authors separated by comma/semicolon, take the first/main one
                if ',' in author_from_ai or ';' in author_from_ai:
                    authors_list = [a.strip() for a in re.split(r'[,;]', author_from_ai)]
                    # For Bulgarian books, prefer Cyrillic name
                    cyrillic_authors = [a for a in authors_list if any('\u0400' <= char <= '\u04FF' for char in a)]
                    if cyrillic_authors:
                        metadata['author'] = cyrillic_authors[0]
                    else:
                        metadata['author'] = authors_list[0]
                    logger.debug(f"Normalized author from '{author_from_ai}' to '{metadata['author']}'")
            
            # If author is missing but we have content, try to extract it
            if not metadata.get('author') and author:
                # Normalize original author too
                if ',' in author or ';' in author:
                    authors_list = [a.strip() for a in re.split(r'[,;]', author)]
                    cyrillic_authors = [a for a in authors_list if any('\u0400' <= char <= '\u04FF' for char in a)]
                    if cyrillic_authors:
                        metadata['author'] = cyrillic_authors[0]
                    else:
                        metadata['author'] = authors_list[0]
                else:
                    metadata['author'] = author
                logger.debug(f"Using normalized original author as fallback: {metadata['author']}")
            
            # Add citations if available
            if citations and 'sources' not in metadata:
                metadata['sources'] = citations
            
            # Add enrichment metadata
            metadata['enrichment_source'] = 'perplexity'
            metadata['enrichment_model'] = self.model
            metadata['enrichment_date'] = datetime.now().isoformat()
            metadata['original_query'] = {
                'title': title, 
                'author': author
            }
            
            # Calculate quality score
            metadata['quality_score'] = self._calculate_quality(metadata)
            
            # Validate metadata
            if not self._validate_metadata(metadata):
                logger.warning("Metadata validation failed")
                return None
            
            return metadata
            
        except Exception as e:
            logger.error(f"Failed to parse Perplexity response: {e}")
            return None
    
    def _extract_json(self, content: str) -> Optional[Dict]:
        """
        Extract JSON from response (may have markdown wrapping)
        
        Args:
            content: Response content
            
        Returns:
            Parsed JSON dictionary or None
        """
        
        # Clean up common issues
        content = content.strip()
        
        try:
            # Try 1: Direct JSON parse
            return json.loads(content)
        except json.JSONDecodeError:
            pass
        
        try:
            # Try 2: Find JSON in markdown code block
            json_match = re.search(
                r'```(?:json)?\s*(\{.*?\})\s*```', 
                content, 
                re.DOTALL | re.IGNORECASE
            )
            if json_match:
                return json.loads(json_match.group(1))
        except json.JSONDecodeError:
            pass
        
        try:
            # Try 3: Find any JSON object
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(0))
        except json.JSONDecodeError:
            pass
        
        logger.warning(f"Could not extract JSON from content: {content[:200]}")
        return None
    
    def _calculate_quality(self, metadata: Dict) -> float:
        """
        Calculate quality score based on completeness and confidence
        
        Args:
            metadata: Parsed metadata
            
        Returns:
            Quality score from 0.0 to 1.0
        """
        
        score = 0.0
        
        # Critical fields (0.6 total)
        if metadata.get('title'): 
            score += 0.20
        if metadata.get('author'): 
            score += 0.20
        if metadata.get('description') and len(metadata['description']) > 50: 
            score += 0.20
        
        # Important fields (0.3 total)
        if metadata.get('publisher'): 
            score += 0.10
        if metadata.get('isbn'): 
            score += 0.10
        if metadata.get('cover_url'): 
            score += 0.10
        
        # Nice-to-have fields (0.1 total)
        if metadata.get('year'): 
            score += 0.03
        if metadata.get('pages'): 
            score += 0.03
        if metadata.get('genres') and len(metadata['genres']) > 0: 
            score += 0.04
        
        # AI confidence boost (if provided)
        ai_confidence = metadata.get('confidence', 0.5)
        if ai_confidence > 0.8:
            score *= 1.05  # 5% bonus for high confidence
        
        # Source quality boost
        sources = metadata.get('sources', [])
        if any('chitanka' in s for s in sources):
            score *= 1.05  # 5% bonus for Chitanka source
        
        return min(1.0, score)
    
    def _validate_metadata(self, metadata: Dict) -> bool:
        """
        Validate that metadata meets minimum requirements
        
        Args:
            metadata: Parsed metadata
            
        Returns:
            True if valid, False otherwise
        """
        
        # Must have at least title and author
        if not metadata.get('title'):
            logger.warning("Missing title in metadata")
            return False
        
        if not metadata.get('author'):
            logger.warning("Missing author in metadata")
            return False
        
        # Quality score must be above threshold
        quality = metadata.get('quality_score', 0)
        if quality < 0.4:
            logger.warning(f"Quality score too low: {quality}")
            return False
        
        return True
    
    async def find_cover_image(
        self, 
        title: str, 
        author: str,
        isbn: Optional[str] = None
    ) -> Optional[str]:
        """
        Specific query for finding cover image URL
        
        Args:
            title: Book title
            author: Book author
            isbn: ISBN if available
            
        Returns:
            Direct URL to cover image or None
        """
        
        logger.info(f"üñºÔ∏è  Searching for cover: {title}")
        
        # Check if book is Bulgarian (has Cyrillic in title)
        has_cyrillic = any('\u0400' <= char <= '\u04FF' for char in title)
        
        if has_cyrillic:
            query = f"""
–ù–∞–º–µ—Ä–∏ –î–ò–†–ï–ö–¢–ï–ù URL –∫—ä–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ –∫–æ—Ä–∏—Ü–∞—Ç–∞ –∑–∞ –ë–™–õ–ì–ê–†–°–ö–ê–¢–ê –∫–Ω–∏–≥–∞:

–ó–ê–ì–õ–ê–í–ò–ï: {title}
–ê–í–¢–û–†: {author}
"""
        else:
            query = f"""
Find DIRECT URL to cover image for the ENGLISH book:

TITLE: {title}
AUTHOR: {author}
"""
        
        if isbn:
            query += f"ISBN: {isbn}\n"
        
        query += """

–í–ê–ñ–ù–û:
- –¢—ä—Ä—Å—è –í–ò–°–û–ö–û –ö–ê–ß–ï–°–¢–í–û –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ –∫–æ—Ä–∏—Ü–∞—Ç–∞
- URL —Ç—Ä—è–±–≤–∞ –¥–∞ —Å–æ—á–∏ –î–ò–†–ï–ö–¢–ù–û –∫—ä–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (.jpg, .png, .webp)
- –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–π —Ñ–æ—Ä–º–∞—Ç –∫–∞—Ç–æ:
  * https://biblioman.chitanka.info/thumb/covers/.../xxx.1000.jpg
  * https://chitanka.info/thumb/book/xxx.250.jpg
  * https://ciela.com/media/catalog/product/.../xxx.jpg

–ò–ó–¢–û–ß–ù–ò–¶–ò –ó–ê –ü–†–û–í–ï–†–ö–ê (–ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç):
1. biblioman.chitanka.info
2. chitanka.info  
3. ciela.com
4. helikon.bg
5. publishers websites (–ö–æ–ª–∏–±—Ä–∏, –ò–∑—Ç–æ–∫-–ó–∞–ø–∞–¥, –•–µ—Ä–º–µ—Å, –ë–∞—Ä–¥)

–û–¢–ì–û–í–û–†–ò –°–ê–ú–û –° URL –∏–ª–∏ "NOT_FOUND":
https://direkten-url-kam-izobrajenie.jpg

–ê–∫–æ –Ω–µ –Ω–∞–º–µ—Ä–∏—à –∫–∞—á–µ—Å—Ç–≤–µ–Ω–∞ –∫–æ—Ä–∏—Ü–∞, –æ—Ç–≥–æ–≤–æ—Ä–∏: NOT_FOUND
"""
        
        try:
            response = await self._search(query)
            
            if not response:
                return None
            
            content = response['choices'][0]['message']['content'].strip()
            
            # Extract URL from response
            url = self._extract_image_url(content)
            
            if url and url != "NOT_FOUND":
                # Verify URL is accessible
                if await self._verify_image_url(url):
                    logger.info(f"‚úÖ Found cover: {url}")
                    return url
                else:
                    logger.warning(f"‚ö†Ô∏è  Cover URL not accessible: {url}")
            
            return None
            
        except Exception as e:
            logger.error(f"Error finding cover: {e}")
            return None
    
    def _extract_image_url(self, text: str) -> Optional[str]:
        """
        Extract image URL from response
        
        Args:
            text: Response text
            
        Returns:
            Image URL or None
        """
        
        # Check for NOT_FOUND
        if "NOT_FOUND" in text.upper():
            return None
        
        # Look for common image URL patterns
        patterns = [
            # Specific Bulgarian sites
            r'https?://biblioman\.chitanka\.info/thumb/covers/[^\s\)]+\.(?:jpg|jpeg|png|webp)',
            r'https?://chitanka\.info/thumb/[^\s\)]+\.(?:jpg|jpeg|png|webp)',
            r'https?://ciela\.com/media/catalog/product/[^\s\)]+\.(?:jpg|jpeg|png|webp)',
            
            # Generic image URLs
            r'https?://[^\s\)]+\.(?:jpg|jpeg|png|gif|webp)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                url = match.group(0)
                # Clean up potential trailing characters
                url = re.sub(r'[,\)\]\'\"]+$', '', url)
                return url
        
        return None
    
    async def _verify_image_url(self, url: str) -> bool:
        """
        Verify that image URL is accessible
        
        Args:
            url: Image URL to verify
            
        Returns:
            True if accessible, False otherwise
        """
        
        try:
            response = await self.client.head(url, timeout=5.0)
            
            if response.status_code == 200:
                # Check content type
                content_type = response.headers.get('content-type', '')
                if 'image' in content_type.lower():
                    return True
            
            # Some servers don't support HEAD, try GET
            response = await self.client.get(
                url, 
                timeout=5.0,
                follow_redirects=True
            )
            return response.status_code == 200
            
        except Exception as e:
            logger.debug(f"Failed to verify image URL: {e}")
            return False
    
    async def close(self):
        """Close HTTP client"""
        await self.client.aclose()
    
    def __repr__(self):
        return f"PerplexityEnricher(model={self.model})"

